# (Обработка естественного языка) Определение токсичности комментариев

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. 
То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Для этого необходимо обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.
Постройте модель со значением метрики качества F1 не меньше 0.75.

## Описание данных

Столбец `text` содержит текст комментария, а `toxic` — целевой признак.

## Используемые инструменты

`BERT` `spacy` `SVC` `pymystem3` `re` `sklearn` `pandas` `numpy` `matplotlib` `plotly` `math`

### Модели

`BERT` `SVC` `DummyClassifier` `LogisticRegression`

### Дополнительно

`TfidfVectorizer` `Lemmatizer` `Lookups` `GridSearchCV`

### Метрики

`f1_score`
